
"""Feature Tweaking

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12mmDQI7o8CFs0raUH39fIKqiM5QTUFnP

**Kickstarter**

Project Brief

The aim of the project is to use the Kickstarter dataset to discover if there is a model for predicting the success or failure of any given kickstarter.

EDA: Basic Data Exploration

Explore the data and see if there are any interesting findings through EDA
"""

import pandas as pd 
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np


df = pd.read_csv('projectdata.csv')

df.head()

df = df[(df['state'] != 'undefined') & (df['state'] != 'live')]
df['state'] = df['state'].replace({'canceled': 'failed', 'suspended': 'failed'})

df.drop(columns=['ID','usd pledged', 'usd_pledged_real'], inplace=True)

df['country'] = df['country'].replace({'N,0"': 'Unknown'})

df['deadline'] = pd.to_datetime(df['deadline'])
df['launched'] = pd.to_datetime(pd.to_datetime(df['launched']).dt.date)

df['target'] = [1 if i == 'successful' else 0 for i in df.state]

df['target'].value_counts()

df['log_backers'] = [0 if i == 0 else np.log10(i) for i in df.backers]

df.name = df.name.fillna('None')

df['name_words'] = [len(i.split()) for i in df.name]
df['name_chars'] = [len(i) for i in df.name]

df['project_length'] = (df.deadline - df.launched).dt.days
df['project_length']

df['project_length'] = df['project_length'].mask(df['project_length'] > 93, 92)

"""# Machine Learning & Modeling

# Encoding/Training

## Set X, y
"""

df.head()



"""### Select Features"""

X = df.drop(['backers', 'name', 'deadline', 'launched', 'state'], axis=1)
X = df.drop(['backers', 'name', 'deadline', 'launched', 'state', 'pledged', 'log_backers', 'goal', 'target'], axis=1)
y = df['target']

for column in ['main_category','category', 'currency', 'country']:
  
    temp = pd.get_dummies(X[column], drop_first=True, prefix=column)
    X = X.join(temp)
    del X[column]

X.head()

#X['usd_goal_real'] = np.log10(X['usd_goal_real'] )





"""### Split Data"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""### Scaling Features"""

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler(feature_range=(1, 10))

X_train = scaler.fit_transform(X_train)

X_test = scaler.transform(X_test)

"""## Modeling"""

from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import recall_score
from sklearn.metrics import precision_score
from sklearn.model_selection import GridSearchCV

"""### Decision Tree"""

from sklearn.tree import DecisionTreeClassifier

model = DecisionTreeClassifier()
model.fit(X_train, y_train)

predictions = model.predict(X_test)
predictions

print('DECISION TREE')

tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()
print('Confusion Matrix')
print([tp,fp])
print([fn,tn])
print()

print('Classification Report')
print(classification_report(y_test, predictions))

print('Accuracy Score')
print(accuracy_score(y_test, predictions))


"""#### Using Tuned Parameters"""

model = DecisionTreeClassifier(max_depth=11)
model.fit(X_train, y_train)

predictions = model.predict(X_test)
predictions

print('DECISION TREE')

tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()
print('Confusion Matrix')
print([tp,fp])
print([fn,tn])
print()

print('Classification Report')
print(classification_report(y_test, predictions))

print('Accuracy Score')
print(accuracy_score(y_test, predictions))

"""### Logistic Regression"""

from sklearn.linear_model import LogisticRegression

model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)

predictions = model.predict(X_test)
predictions

print('LOGISTIC REGRESSION')
tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()
print('Confusion Matrix')
print([tp,fp])
print([fn,tn])
print()

print('Classification Report')
print(classification_report(y_test, predictions))

print('Accuracy Score')
print(accuracy_score(y_test, predictions))



"""#### Using Tuned Parameters"""

model = LogisticRegression(max_iter=1000, C=0.95959)
model.fit(X_train, y_train)

predictions = model.predict(X_test)
predictions

print('LOGISTIC REGRESSION')

tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()
print('Confusion Matrix')
print([tp,fp])
print([fn,tn])
print()

print('Classification Report')
print(classification_report(y_test, predictions))

print('Accuracy Score')
print(accuracy_score(y_test, predictions))

"""### Random Forest"""

from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier(n_estimators=100, max_leaf_nodes=16, n_jobs=-1, random_state=42)
model.fit(X_train, y_train)

predictions = model.predict(X_test)
predictions

print('RANDOM FOREST')
tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()
print('Confusion Matrix')
print([tp,fp])
print([fn,tn])
print()

print('Classification Report')
print(classification_report(y_test, predictions))

print('Accuracy Score')
print(accuracy_score(y_test, predictions))


"""#### Using Tuned Parameters"""

model = RandomForestClassifier(max_depth=15, n_estimators=100, n_jobs=-1, random_state=42)
model.fit(X_train, y_train)

predictions = model.predict(X_test)
predictions

print('RANDOM FOREST')

tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()
print('Confusion Matrix')
print([tp,fp])
print([fn,tn])
print()

print('Classification Report')
print(classification_report(y_test, predictions))

print('Accuracy Score')
print(accuracy_score(y_test, predictions))


"""### ADABOOST"""

from sklearn.ensemble import AdaBoostClassifier

model = AdaBoostClassifier(
    n_estimators=70,learning_rate=0.05)
model.fit(X_train, y_train)

predictions = model.predict(X_test)
predictions

print('AdaBoost')

tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()
print('Confusion Matrix')
print([tp,fp])
print([fn,tn])
print()

print('Classification Report')
print(classification_report(y_test, predictions))

print('Accuracy Score')
print(accuracy_score(y_test, predictions))


"""#### Using Tuned Parameters"""

from sklearn.ensemble import AdaBoostClassifier

model = AdaBoostClassifier(
    n_estimators=150,learning_rate=0.1)
model.fit(X_train, y_train)

predictions = model.predict(X_test)
predictions

print('AdaBoost')

tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()
print('Confusion Matrix')
print([tp,fp])
print([fn,tn])
print()

print('Classification Report')
print(classification_report(y_test, predictions))

print('Accuracy Score')
print(accuracy_score(y_test, predictions))




from xgboost import XGBClassifier

model = XGBClassifier(learning_rate=0.05, n_jobs=-1)
model.fit(X_train, y_train)
predictions = model.predict(X_test)
predictions

print('XGBoost')

tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()
print('Confusion Matrix')
print([tp,fp])
print([fn,tn])
print()

print('Classification Report')
print(classification_report(y_test, predictions))

print('Accuracy Score')
print(accuracy_score(y_test, predictions))


print('TUNED XGB')
"""#### Using Tuned Parameters"""

model = XGBClassifier(subsample=0.7, n_estimators=100, min_child_weight=3, max_depth=7, learning_rate=0.1)
model.fit(X_train, y_train)

predictions = model.predict(X_test)
predictions

print('XGBOOST')

tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()
print('Confusion Matrix')
print([tp,fp])
print([fn,tn])
print()

print('Classification Report')
print(classification_report(y_test, predictions))

print('Accuracy Score')
print(accuracy_score(y_test, predictions))